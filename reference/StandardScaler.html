<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="The standard score of a sample x is calculated as:
$$z = \frac{(x - u)}{s}$$
where \(u\) is the mean of the training samples or 0 if with_mean = FALSE, and \(s\) is the standard deviation of the training samples or 1 if
with_std = FALSE.
Standardization of a dataset is a common requirement for many machine
learning estimators: they might behave badly if the individual features do
not more or less look like standard normally distributed data (e.g. Gaussian
with 0 mean and unit variance).
For instance many elements used in the objective function of a learning
algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2
regularizers of linear models) assume that all features are centered around 0
and have variance in the same order. If a feature has a variance that is
orders of magnitude larger than others, it might dominate the objective
function and make the estimator unable to learn from other features correctly
as expected.
This scaler can also be applied to sparse CSR or CSC matrices by passing
with_mean = FALSE to avoid breaking the sparsity structure of the data."><title>Standardizes features by removing the mean and scaling to unit variance — StandardScaler • rgudhi</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Standardizes features by removing the mean and scaling to unit variance — StandardScaler"><meta property="og:description" content="The standard score of a sample x is calculated as:
$$z = \frac{(x - u)}{s}$$
where \(u\) is the mean of the training samples or 0 if with_mean = FALSE, and \(s\) is the standard deviation of the training samples or 1 if
with_std = FALSE.
Standardization of a dataset is a common requirement for many machine
learning estimators: they might behave badly if the individual features do
not more or less look like standard normally distributed data (e.g. Gaussian
with 0 mean and unit variance).
For instance many elements used in the objective function of a learning
algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2
regularizers of linear models) assume that all features are centered around 0
and have variance in the same order. If a feature has a variance that is
orders of magnitude larger than others, it might dominate the objective
function and make the estimator unable to learn from other features correctly
as expected.
This scaler can also be applied to sparse CSR or CSC matrices by passing
with_mean = FALSE to avoid breaking the sparsity structure of the data."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">rgudhi</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/lmjl-alea/rgudhi/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Standardizes features by removing the mean and scaling to unit variance</h1>
      <small class="dont-index">Source: <a href="https://github.com/lmjl-alea/rgudhi/blob/HEAD/R/sklearn-scalers.R" class="external-link"><code>R/sklearn-scalers.R</code></a></small>
      <div class="d-none name"><code>StandardScaler.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>The standard score of a sample x is calculated as:
$$z = \frac{(x - u)}{s}$$
where \(u\) is the mean of the training samples or 0 if <code>with_mean = FALSE</code>, and \(s\) is the standard deviation of the training samples or 1 if
<code>with_std = FALSE</code>.</p>
<p>Standardization of a dataset is a common requirement for many machine
learning estimators: they might behave badly if the individual features do
not more or less look like standard normally distributed data (e.g. Gaussian
with 0 mean and unit variance).</p>
<p>For instance many elements used in the objective function of a learning
algorithm (such as the RBF kernel of Support Vector Machines or the L1 and L2
regularizers of linear models) assume that all features are centered around 0
and have variance in the same order. If a feature has a variance that is
orders of magnitude larger than others, it might dominate the objective
function and make the estimator unable to learn from other features correctly
as expected.</p>
<p>This scaler can also be applied to sparse CSR or CSC matrices by passing
<code>with_mean = FALSE</code> to avoid breaking the sparsity structure of the data.</p>
    </div>


    <div class="section level2">
    <h2 id="super-classes">Super classes<a class="anchor" aria-label="anchor" href="#super-classes"></a></h2>
    <p><code>rgudhi::PythonClass</code> -&gt; <code>rgudhi::SKLearnClass</code> -&gt; <code><a href="BaseScaler.html">rgudhi::BaseScaler</a></code> -&gt; <code>StandardScaler</code></p>
    </div>
    <div class="section level2">
    <h2 id="methods">Methods<a class="anchor" aria-label="anchor" href="#methods"></a></h2>
    
<div class="section">
<h3 id="public-methods">Public methods<a class="anchor" aria-label="anchor" href="#public-methods"></a></h3>

<ul><li><p><a href="#method-StandardScaler-new"><code>StandardScaler$new()</code></a></p></li>
<li><p><a href="#method-StandardScaler-clone"><code>StandardScaler$clone()</code></a></p></li>
</ul></div><p><details><summary>Inherited methods</summary><ul><li><span class="pkg-link" data-pkg="rgudhi" data-topic="PythonClass" data-id="get_python_class"><a href="PythonClass.html#method-get_python_class"><code>rgudhi::PythonClass$get_python_class()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="PythonClass" data-id="set_python_class"><a href="PythonClass.html#method-set_python_class"><code>rgudhi::PythonClass$set_python_class()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="apply"><a href="SKLearnClass.html#method-apply"><code>rgudhi::SKLearnClass$apply()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="fit"><a href="SKLearnClass.html#method-fit"><code>rgudhi::SKLearnClass$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="fit_transform"><a href="SKLearnClass.html#method-fit_transform"><code>rgudhi::SKLearnClass$fit_transform()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="get_params"><a href="SKLearnClass.html#method-get_params"><code>rgudhi::SKLearnClass$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="set_params"><a href="SKLearnClass.html#method-set_params"><code>rgudhi::SKLearnClass$set_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="rgudhi" data-topic="SKLearnClass" data-id="transform"><a href="SKLearnClass.html#method-transform"><code>rgudhi::SKLearnClass$transform()</code></a></span></li>
</ul></details></p><hr><a id="method-StandardScaler-new"></a><div class="section">
<h3 id="method-new-">Method <code>new()</code><a class="anchor" aria-label="anchor" href="#method-new-"></a></h3>
<p>The StandardScaler class constructor.</p><div class="section">
<h4 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va"><a href="../reference/StandardScaler.html">StandardScaler</a></span><span class="op">$</span><span class="fu">new</span><span class="op">(</span>copy <span class="op">=</span> <span class="cn">TRUE</span>, with_mean <span class="op">=</span> <span class="cn">TRUE</span>, with_std <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h4>
<p></p><div class="arguments"><dl><dt><code>copy</code></dt>
<dd><p>A boolean value specifying whether to perform in-place
scaling and avoid a copy (if the input is already a numpy array).
Defaults to <code>TRUE</code>.</p></dd>


<dt><code>with_mean</code></dt>
<dd><p>A boolean value specifying whether to center the data
before scaling. This does not work (and will raise an exception) when
attempted on sparse matrices, because centering them entails building a
dense matrix which in common use cases is likely to be too large to fit
in memory. Defaults to <code>TRUE</code>.</p></dd>


<dt><code>with_std</code></dt>
<dd><p>A boolean value specifying whether to scale the data to
unit variance (or equivalently, unit standard deviation). Defaults to
<code>TRUE</code>.</p></dd>


</dl><p></p></div>
</div>
<div class="section">
<h4 id="returns">Returns<a class="anchor" aria-label="anchor" href="#returns"></a></h4>
<p>An object of class StandardScaler.</p>
</div>

</div><p></p><hr><a id="method-StandardScaler-clone"></a><div class="section">
<h3 id="method-clone-">Method <code>clone()</code><a class="anchor" aria-label="anchor" href="#method-clone-"></a></h3>
<p>The objects of this class are cloneable with this method.</p><div class="section">
<h4 id="usage-1">Usage<a class="anchor" aria-label="anchor" href="#usage-1"></a></h4>
<p></p><div class="r"><div class="sourceCode"><pre><code><span><span class="va">StandardScaler</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span>deep <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div><p></p></div>
</div>

<div class="section">
<h4 id="arguments-1">Arguments<a class="anchor" aria-label="anchor" href="#arguments-1"></a></h4>
<p></p><div class="arguments"><dl><dt><code>deep</code></dt>
<dd><p>Whether to make a deep clone.</p></dd>


</dl><p></p></div>
</div>

</div>

    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="va">ss</span> <span class="op">&lt;-</span> <span class="va">StandardScaler</span><span class="op">$</span><span class="fu">new</span><span class="op">(</span><span class="op">)</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Aymeric Stamm.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

